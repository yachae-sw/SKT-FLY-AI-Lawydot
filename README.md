# 나만의 법률 개인 비서 (My own legal secretary)

### 🧑‍🤝‍🧑맴버 구성

|                                                                                   **채성원**                                                                                   |                                                                                   **김윤서**                                                                                    |
| :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------: | :-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------: |
| [<img src="https://github.com/yachae-sw/SKT-FLY-AI-Lawydot/assets/93850398/42c9e675-6126-473d-91b8-f59fcf165e08" width="120" > <br/> @yachae-sw](https://github.com/yachae-sw) | [<img src="https://github.com/yachae-sw/SKT-FLY-AI-Lawydot/assets/93850398/2761f43b-bad2-46bd-9bbf-735cb7fa8a1b" width="120"> <br/> @yoonseo111](https://github.com/yoonseo111) |

## 👻프로젝트 소개

- 최근 사회 초년생에게 자주 발생하는 **부동산 사기** 문제
- 해결하기 위한 **가이드라인을 이해하기 쉽게** 제공해드립니다

  ### 특징

  - 전세 사기는 전국민의 관심을 받을 만큼 심각한 사회 문제이며 아직까지도 많은 피해자가 발생하고 있다.
  - 기존의 법률 플랫폼에서 사용자는 "내가 처한 상황을 어떻게 얼마나 설명을 해야할까?"와 같은 고민을 한다.
  - 부동산 종류, 임대 유형, 가해자, 피해 금액, 간단한 상황 총 5가지의 고정 질문을 통해 사용자의 고민을 덜어주고자 한다.
  - 위 질문을 바탕으로 사용자에게 관련 법률, 상황 요약, 해결 절차, 필요 서류 목록, 유사 판례를 알 수 있다.

  ### 린 캔버스

## :star:핵심 기술

- Gemini Pro(LLM) : Google DeepMind에서 개발한 다중 모드 대형 언어 모델이다. 텍스트, 오디오, 이미지, 영상 등 다양한 입력값을 원활하게 이해하고 받아 추론할 수 있으며, 기존 멀티모달 모델보다 훨씬 뛰어난 성능을 보여준다.
- Chain of Thought(CoT) : AI가 단순히 답을 내놓는 것이 아니라, 답에 도달하기까지 어떤 과정을 거쳤는지 설명할 수 있도록 한다.
- Retrieval-Augmented Generation(RAG) : 기존의 검색 기술과 생성 모델을 결합하여 보다 정확하고 유용한 법률 정보를 제공하도록 한다.
- Bert : 구글의 Devlin(2018)이 제안한 BERT는 사전 학습된 대용량의 레이블링 되지 않는(unlabeled) 데이터를 이용하여 언어 모델(Language Model)을 학습하고 이를 토대로 특정 작업( 문서 분류, 질의응답, 번역 등)을 위한 신경망을 추가하는 전이 학습 방법이다.
  - Token Embeddings : Word piece 임베딩 방식을 사용하여 가장 긴 길이의 sub-word를 하나의 단위로 만드는 과정
  - Segment Embeddings : 토큰으로 나누어진 단어들을 다시 하나의 문장으로 만드는 과정
  - Position Embeddings : 토큰의 순서를 인코딩하는 과정
- Cosine Similarity : 코사인 유사도는 두 벡터 간의 코사인 각도를 이용하여 구할 수 있는 두 벡터의 유사도를 의미한다.

  ### 📅개발 기간

  - 2024.01.02 - 2024.02.29

  ### :hammer:개발 환경

  - Front : HTML, React, styled-components
  - Back-end : express
  - 인공지능(LLM api & prompt) : Python, JavaScript
  - UI/UX : Figma
  - 버전 및 이슈관리 : Github, Github Issues, Github organizations
  - 협업 툴 : Notion, Discord, Github

  ### 시스템 구성도

  ### 페이지별 기능

## 향후 개선 방향

## 프로젝트 후기
