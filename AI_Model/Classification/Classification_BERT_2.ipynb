{"cells":[{"cell_type":"code","source":["pip install konlpy"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_obZaqpS5Fu2","executionInfo":{"status":"ok","timestamp":1706610164770,"user_tz":-540,"elapsed":8686,"user":{"displayName":"김윤서","userId":"14816156544566013232"}},"outputId":"1fb68619-d46c-45e8-bc27-c295d5a35570"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting konlpy\n","  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting JPype1>=0.7.0 (from konlpy)\n","  Downloading JPype1-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (488 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m488.6/488.6 kB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (4.9.4)\n","Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.23.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (23.2)\n","Installing collected packages: JPype1, konlpy\n","Successfully installed JPype1-1.5.0 konlpy-0.6.0\n"]}]},{"cell_type":"code","source":["pip install scikit-learn"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iVuVzUq-90PV","executionInfo":{"status":"ok","timestamp":1706611405382,"user_tz":-540,"elapsed":8475,"user":{"displayName":"김윤서","userId":"14816156544566013232"}},"outputId":"4cd0581b-1a1a-4e9a-df68-f1fe04fa399b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.23.5)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n"]}]},{"cell_type":"code","source":["pip install gensim scikit-learn"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"thKxe0199mqT","executionInfo":{"status":"ok","timestamp":1706611419820,"user_tz":-540,"elapsed":6929,"user":{"displayName":"김윤서","userId":"14816156544566013232"}},"outputId":"bcfc8517-1c89-4d25-d215-6512dfb755dd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.23.5)\n","Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.4)\n","Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n"]}]},{"cell_type":"code","source":["from gensim.models import Word2Vec\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, classification_report\n","import numpy as np"],"metadata":{"id":"qnhMJ_Oz98sx"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"63s3Oxls_FtV","executionInfo":{"status":"ok","timestamp":1706610869226,"user_tz":-540,"elapsed":10050,"user":{"displayName":"김윤서","userId":"14816156544566013232"}},"outputId":"b854b821-009c-4467-e2fc-4de69155aa00"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.9555555555555556\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","          민사       0.94      0.94      0.94        18\n","          형사       0.96      0.96      0.96        27\n","\n","    accuracy                           0.96        45\n","   macro avg       0.95      0.95      0.95        45\n","weighted avg       0.96      0.96      0.96        45\n","\n"]}],"source":["# 필요한 라이브러리를 임포트\n","import os\n","from xml.etree import ElementTree\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import classification_report, accuracy_score\n","from sklearn.pipeline import Pipeline\n","import os\n","from xml.etree import ElementTree\n","import json\n","\n","# 폴더 내의 모든 파일 경로를 가져오는 함수\n","def get_file_paths(directory):\n","    file_paths = [os.path.join(directory, filename) for filename in os.listdir(directory) if os.path.isfile(os.path.join(directory, filename))]\n","    return file_paths\n","\n","def extract_korean_texts(directory):\n","    file_paths = get_file_paths(directory)  # 디렉토리 내의 모든 파일 경로를 가져옴\n","    texts = []\n","    for file_path in file_paths:\n","        with open(file_path, 'r', encoding='utf-8') as file:\n","            content = json.load(file)\n","            if 'facts' in content:\n","                # 'facts' 부분만 문자열로 변환하여 추가\n","                facts_text = json.dumps(content['facts'], ensure_ascii=False)\n","                texts.append(facts_text)\n","    return texts\n","\n","\n","# 폴더 경로 지정\n","civil_case_directory = '/content/drive/MyDrive/SKT_FLY_AI/Project/civil'  # 민사 사건 파일이 있는 폴더 경로\n","criminal_case_directory = '/content/drive/MyDrive/SKT_FLY_AI/Project/criminal'  # 형사 사건 파일이 있는 폴더 경로\n","\n","# 데이터 로드\n","civil_texts = extract_korean_texts(civil_case_directory)\n","criminal_texts = extract_korean_texts(criminal_case_directory)\n","\n","# 민사 및 형사 텍스트 데이터를 하나의 데이터셋으로 결합\n","texts = civil_texts + criminal_texts  # 전체 텍스트 데이터\n","labels = ['민사'] * len(civil_texts) + ['형사'] * len(criminal_texts)  # 민사: 0, 형사: 1\n","\n","from konlpy.tag import Okt\n","\n","# Okt 객체를 생성합니다.\n","okt = Okt()\n","\n","# 사용자 정의 불용어 리스트를 정의합니다.\n","stop_words = ['는', '의', '에', '을', '를', '과', '와', '이', '가', '도', '으로', '로', '에서', '하다', '형사', '민사', '형법', '민법']\n","\n","# 민사 및 형사 텍스트가 저장된 변수를 정의합니다.\n","# civil_texts = [\"민사 예시 텍스트 데이터\", \"민사 텍스트의 또 다른 예시\"]\n","# criminal_texts = [\"형사 예시 텍스트 데이터\", \"형사 텍스트의 또 다른 예시\"]\n","\n","# 텍스트를 토큰화합니다.\n","civil_tokens = [okt.morphs(text) for text in civil_texts]\n","criminal_tokens = [okt.morphs(text) for text in criminal_texts]\n","\n","# 불용어를 제거합니다.\n","civil_processed = [[word for word in tokens if word not in stop_words] for tokens in civil_tokens]\n","criminal_processed = [[word for word in tokens if word not in stop_words] for tokens in criminal_tokens]\n","\n","# 각 리스트의 단어들을 집합으로 변환합니다.\n","civil_word_set = set(word for sublist in civil_processed for word in sublist)\n","criminal_word_set = set(word for sublist in criminal_processed for word in sublist)\n","\n","# 두 집합의 교집합(공통 단어)을 찾습니다.\n","common_words = civil_word_set.intersection(criminal_word_set)\n","\n","# 공통 단어를 제거합니다.\n","civil_final = [[word for word in sublist if word not in common_words] for sublist in civil_processed]\n","criminal_final = [[word for word in sublist if word not in common_words] for sublist in criminal_processed]\n","\n","# 결과를 변수에 저장합니다.\n","civil_texts = [' '.join(tokens) for tokens in civil_final]\n","criminal_texts = [' '.join(tokens) for tokens in criminal_final]\n","\n","\n","\n","# 데이터를 훈련 세트와 테스트 세트로 분할\n","X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.25, random_state=42)\n","\n","# 파이프라인 구축: TF-IDF 벡터라이저와 로지스틱 회귀 분류기\n","pipeline = Pipeline([\n","    ('tfidf', TfidfVectorizer()),\n","    ('classifier', LogisticRegression(solver='liblinear')),\n","])\n","\n","# 모델 훈련\n","pipeline.fit(X_train, y_train)\n","\n","# 테스트 데이터에 대한 예측\n","y_pred = pipeline.predict(X_test)\n","\n","# 성능 평가\n","accuracy = accuracy_score(y_test, y_pred)\n","classification_rep = classification_report(y_test, y_pred)\n","\n","# 결과 출력\n","print(\"Accuracy:\", accuracy)\n","print(\"Classification Report:\\n\", classification_rep)"]},{"cell_type":"code","source":["# Word2Vec 모델을 훈련시킵니다. 여기서는 이미 토큰화된 데이터를 사용합니다.\n","model_w2v = Word2Vec(sentences=civil_tokens + criminal_tokens, vector_size=100, window=5, min_count=1, workers=4)\n","\n","# 단어 벡터의 평균을 구하는 함수를 정의합니다.\n","def get_average_word2vec(tokens_list, vector, generate_missing=False, k=100):\n","    if len(tokens_list) < 1:\n","        return np.zeros(k)\n","    if generate_missing:\n","        vectorized = [vector[word] if word in vector else np.random.rand(k) for word in tokens_list]\n","    else:\n","        vectorized = [vector[word] if word in vector else np.zeros(k) for word in tokens_list]\n","    length = len(vectorized)\n","    summed = np.sum(vectorized, axis=0)\n","    averaged = np.divide(summed, length)\n","    return averaged\n","\n","# 각 텍스트에 대한 평균 Word2Vec 벡터를 계산합니다.\n","X = np.array([get_average_word2vec(tokens, model_w2v.wv, generate_missing=True) for tokens in civil_tokens + criminal_tokens])\n","\n","# 레이블을 생성합니다.\n","labels = [0] * len(civil_texts) + [1] * len(criminal_texts)  # 0은 민사, 1은 형사\n","\n","# 데이터를 훈련 세트와 테스트 세트로 분할합니다.\n","X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.3, random_state=42)\n","\n","# 로지스틱 회귀 분석 모델을 생성하고 훈련합니다.\n","model_lr = LogisticRegression()\n","model_lr.fit(X_train, y_train)\n","\n","# 테스트 데이터에 대한 예측을 수행합니다.\n","y_pred = model_lr.predict(X_test)\n","\n","# 정확도와 분류 리포트를 출력합니다.\n","print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n","print(classification_report(y_test, y_pred))"],"metadata":{"id":"ybRJJByJ-Exj","executionInfo":{"status":"ok","timestamp":1706611466050,"user_tz":-540,"elapsed":1400,"user":{"displayName":"김윤서","userId":"14816156544566013232"}},"outputId":"87377ae9-9864-44fa-cfbc-0fd9404cb107","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.7407407407407407\n","              precision    recall  f1-score   support\n","\n","           0       0.90      0.41      0.56        22\n","           1       0.70      0.97      0.82        32\n","\n","    accuracy                           0.74        54\n","   macro avg       0.80      0.69      0.69        54\n","weighted avg       0.78      0.74      0.71        54\n","\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":286,"status":"ok","timestamp":1706611475332,"user":{"displayName":"김윤서","userId":"14816156544566013232"},"user_tz":-540},"id":"xwmRIcVaF-vD","outputId":"0c6b21e2-defc-4b7b-ad26-8d3fc96dd88a"},"outputs":[{"output_type":"stream","name":"stdout","text":["예측된 분류: 민사\n"]}],"source":["new_example_file_path = '/content/drive/MyDrive/SKT_FLY_AI/Project/86가합493.json'\n","pred_texts = []\n","with open(new_example_file_path, 'r', encoding='utf-8') as file:\n","            new_example_text = json.load(file)\n","            if 'facts' in new_example_text:\n","                # 'facts' 부분만 문자열로 변환하여 추가\n","                facts_text = json.dumps(new_example_text['facts'], ensure_ascii=False)\n","                texts.append(facts_text)\n","\n","pred_texts.append(json.dumps(new_example_text, ensure_ascii=False))\n","\n","new_example_prediction = pipeline.predict(pred_texts)\n","\n","# 예측 결과 출력\n","print(\"예측된 분류:\", new_example_prediction[0])\n"]},{"cell_type":"code","source":["new_example_file_path = '/content/drive/MyDrive/SKT_FLY_AI/Project/2010고단3085.json'\n","pred_texts = []\n","with open(new_example_file_path, 'r', encoding='utf-8') as file:\n","            new_example_text = json.load(file)\n","            if 'facts' in new_example_text:\n","                # 'facts' 부분만 문자열로 변환하여 추가\n","                facts_text = json.dumps(new_example_text['facts'], ensure_ascii=False)\n","                texts.append(facts_text)\n","\n","pred_texts.append(json.dumps(new_example_text, ensure_ascii=False))\n","\n","new_example_prediction = pipeline.predict(pred_texts)\n","\n","# 예측 결과 출력\n","print(\"예측된 분류:\", new_example_prediction[0])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fKHvC2-66tmd","executionInfo":{"status":"ok","timestamp":1706611477195,"user_tz":-540,"elapsed":271,"user":{"displayName":"김윤서","userId":"14816156544566013232"}},"outputId":"5cccf582-f533-400d-a400-6ee43835c75b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["예측된 분류: 형사\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lin5NsQ7uQrO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706611478899,"user_tz":-540,"elapsed":318,"user":{"displayName":"김윤서","userId":"14816156544566013232"}},"outputId":"6314e212-aa0e-488c-f889-05876c5b6fea"},"outputs":[{"output_type":"stream","name":"stdout","text":["예측된 분류: 형사\n"]}],"source":["new_text = [\"피고인은 조현병으로 인하여 사물을 변별할 능력이나 의사를 결정할 능력이 미약한 상태에서 사람을 죽였다.\"]\n","\n","new_example_prediction2 = pipeline.predict(new_text)\n","\n","# 예측 결과 출력\n","print(\"예측된 분류:\", new_example_prediction2[0])"]},{"cell_type":"code","source":["new_text = [\"내가 화가 나서 옆사람을 칼로 찔렀어.\"]\n","\n","new_example_prediction2 = pipeline.predict(new_text)\n","\n","# 예측 결과 출력\n","print(\"예측된 분류:\", new_example_prediction2[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IdaonR6G7aRy","executionInfo":{"status":"ok","timestamp":1706611480488,"user_tz":-540,"elapsed":301,"user":{"displayName":"김윤서","userId":"14816156544566013232"}},"outputId":"59f52568-b183-4c02-f636-4e2d5339b94e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["예측된 분류: 형사\n"]}]},{"cell_type":"code","source":["new_text = [\"나 연예인인데 소속사가 계약위반을 했어.\"]\n","\n","new_example_prediction2 = pipeline.predict(new_text)\n","\n","# 예측 결과 출력\n","print(\"예측된 분류:\", new_example_prediction2[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IydgQtxY7g5F","executionInfo":{"status":"ok","timestamp":1706611481743,"user_tz":-540,"elapsed":6,"user":{"displayName":"김윤서","userId":"14816156544566013232"}},"outputId":"ff2a4568-0354-49b0-efd5-d4e5eefa12c3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["예측된 분류: 형사\n"]}]}],"metadata":{"colab":{"provenance":[],"mount_file_id":"1YQigh_RQgvzhFEiBUwi6nD1jFeQgTGZE","authorship_tag":"ABX9TyOHBb0yL0HfJhnaVWcjRU2a"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}